exp:
  name: sparc_ppo_longctx
data:
  datasets: [narrativeqa, hotpotqa, triviaqa, nq_long]  # All available datasets
  dataset_order: [narrativeqa, hotpotqa, triviaqa, nq_long]  # From easiest to hardest
  validation_cache_dir: "data/validation_cache" # Relative path to validation cache
  curriculum_enabled: true  # Enable dataset curriculum
  qa_thresholds: [0.3, 0.4, 0.5]  # QA score thresholds to unlock next dataset
  split: train
  dataset_config:  # Dataset-specific configuration
    narrativeqa:
      use_summaries: true  # Use summaries instead of full stories for NarrativeQA
    triviaqa:
      skip_validation: false      # Option to skip TriviaQA validation data if it causes issues
      use_synthetic_fallback: true # Generate synthetic context when real context isn't found
      include_aliases: true       # Include alias information in context when available
      debug_context_paths: false  # Print detailed context extraction paths for debugging
    nq_long:
      use_synthetic_context: true # If True, creates synthetic context from question+answers
      max_context_length: 1024    # Maximum context length to use when real context is available
      context_padding: true       # Add generic padding to short contexts to make task more realistic
env:
  chunk_size: 256
  max_window: 2048
  reward:
    alpha: 1.0            # Weight for QA score
    beta_keep: -0.01    # Cost per token KEPT in context window
    beta_compress: -0.05 # Cost per token in COMPRESSED chunk (if applicable)
    gamma_step: -0.01   # Flat cost applied per step, regardless of action
curriculum:
  enabled: true
  start_chunks: 2
  max_chunks: 10
  growth_steps: 50_000
model:
  tokenizer: NousResearch/Meta-Llama-3.1-8B
  embed_dim: 128
  vocab_size: 128256
  net_arch: [{pi: [128, 64], vf: [128, 64]}]
train:
  n_envs: 8
  total_steps: 1_000_000
  lr: 3e-5
  n_steps: 1024
  batch_size: 256
  gamma: 0.99
  seed: 42  # Random seed for training
  gae_lambda: 0.95
  clip_range: 0.2
wandb:
  project: SPARC
eval:
  frequency: 100   # Evaluate every 10k steps
  episodes: 1      # Number of episodes to evaluate on
  deterministic: true
  save_path: "./checkpoints/" # Directory to save best model checkpoints
  seed: 123  # Random seed for evaluation
  name_prefix: "sparc_best_model" # Prefix for the best model filename
  validation_cache_size: 500  # Number of validation examples to cache for deterministic evaluation
